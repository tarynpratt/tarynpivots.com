<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>distributed-availability-group on Taryn Pratt - Pivots and other SQL fun</title>
    <link>https://tarynpivots.com/tags/distributed-availability-group/</link>
    <description>Recent content in distributed-availability-group on Taryn Pratt - Pivots and other SQL fun</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 18 Dec 2020 04:00:00 +0000</lastBuildDate><atom:link href="https://tarynpivots.com/tags/distributed-availability-group/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Syncing Logins Between Availability Group Replicas</title>
      <link>https://tarynpivots.com/post/2020/syncing-logins-between-availablity-group-replicas/</link>
      <pubDate>Fri, 18 Dec 2020 04:00:00 +0000</pubDate>
      
      <guid>https://tarynpivots.com/post/2020/syncing-logins-between-availablity-group-replicas/</guid>
      <description>I mentioned this in a few previous posts, but for for those who may have missed it or forgotten, here’s a quick refresher - we use Always On Availability Groups at Stack Overflow on all of our main production servers running the network of public Q&amp;amp;A sites, Jobs, and Stack Overflow for Teams. It&amp;rsquo;s a great way to implement disaster recovery for a SQL Server environment.
Always On Availability Groups can support up to nine availability replicas, and while we don’t use anywhere near that many replicas in each of our clusters, we do have 2 replicas per cluster (3 servers total), with the replicas being used as a readable secondary.</description>
    </item>
    
    <item>
      <title>SQL Server 2019 Aggressive Clustered Columnstore Cleanup</title>
      <link>https://tarynpivots.com/post/aggressive-clustered-columnstore-cleanup/</link>
      <pubDate>Fri, 24 Apr 2020 04:00:00 +0000</pubDate>
      
      <guid>https://tarynpivots.com/post/aggressive-clustered-columnstore-cleanup/</guid>
      <description>In late March 2020, we upgraded our production SQL Servers to SQL Server 2019with CU3. After finishing the upgrade, we hit an issue with clustered columnstorethat we hadn&amp;rsquo;t experienced in the previous version of SQL, SQL Server 2017. The issue also wasn&amp;rsquo;t something we encountered during our extensive testing on various servers in development, which dated back to September 2019. The problem has been mitigated, but I wanted to share our experience.</description>
    </item>
    
    <item>
      <title>The Perils of Querying SQL Server Replicas Under Load</title>
      <link>https://tarynpivots.com/post/perils-querying-sql-replica-under-load/</link>
      <pubDate>Wed, 15 Jan 2020 06:00:38 +0000</pubDate>
      
      <guid>https://tarynpivots.com/post/perils-querying-sql-replica-under-load/</guid>
      <description>Last week at Stack Overflow we had an internal hack-a-thon, or as we call it, a make-a-thon. I was on the bug-bashing team, which is the team that attempts to fix smallish bugs we haven’t gotten around to fixing, due to other time-constraints. I was tagged to investigate a bugabout duplicate badges being awarded because it looked to possibly be an easy fix in SQL. At first glance it looked simple enough, but once I started digging in, I figured out very quickly it wouldn’t be.</description>
    </item>
    
    <item>
      <title>Hitting Parallel_Redo_Flow_Control waits with Availability Groups</title>
      <link>https://tarynpivots.com/post/parallel-redo-flow-control-waits-and-availability-groups/</link>
      <pubDate>Mon, 09 Dec 2019 06:00:38 +0000</pubDate>
      
      <guid>https://tarynpivots.com/post/parallel-redo-flow-control-waits-and-availability-groups/</guid>
      <description>In late June 2019, June 26thto be exact, we experienced an outage on Stack Overflow for about 11 minutes. It&amp;rsquo;s not unusual that we had an outage. They happen. Not often, but they do still happen. This one, however, was a little different because it was caused by a maintenance job that was running on our primary SQL Server for Stack Overflow.
The job that caused it was something I&amp;rsquo;d noticed about a month prior, but had stopped itbefore an actual outage occurred.</description>
    </item>
    
    <item>
      <title>How Stack Overflow upgraded from Windows Server 2012</title>
      <link>https://tarynpivots.com/post/how-stack-overflow-upgraded-from-windows-2012/</link>
      <pubDate>Thu, 18 Jul 2019 06:00:38 +0000</pubDate>
      
      <guid>https://tarynpivots.com/post/how-stack-overflow-upgraded-from-windows-2012/</guid>
      <description>Warning: This post is long. While working through this massive server upgrade/migration process, tears were shed, many cuss words were said, along with a general feeling of frustration, which ultimately culminated into extreme happiness once the migration was completed. The scale and complexity of the implementation factor into the length of this post, and I’ll share my thought process on how this was executed, so here goes.
Last year, when we upgraded to SQL Server 2017 we didn&amp;rsquo;t make any changes to the operating system on our main production servers.</description>
    </item>
    
    <item>
      <title>How we upgraded Stack Overflow to SQL Server 2017</title>
      <link>https://tarynpivots.com/post/how-we-upgraded-stackoverflow-to-sql-server-2017/</link>
      <pubDate>Wed, 07 Nov 2018 19:00:38 +0000</pubDate>
      
      <guid>https://tarynpivots.com/post/how-we-upgraded-stackoverflow-to-sql-server-2017/</guid>
      <description>This post has been rattling around in my head for months, and with SQL Server 2019on the horizon, I figured I&amp;rsquo;d finally put my thoughts down, especially since I know we might hit some of the same issues when we upgrade.
A quick background, when I became the DBA at Stack Overflow, we had various versions of SQL Server in place — the majority were at some level of SQL Server 2016, each with a different CU or SP installed.</description>
    </item>
    
  </channel>
</rss>
